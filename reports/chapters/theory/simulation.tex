\section{Optimisation \& sampling methods}
\label{sec:optimisation}
In this work, computational modelling methods have been applied to important scattering problems.
The aim of many modelling problems is to optimise a series of parameters such that a minimum in some parameter-dependent metric is found.
While, in other circumstances, the aim is to sample the parametric search-space of a particular problem.
The problem of parameter optimisation and sampling is a massive area of mathematics and computer science and is it not possible to introduce the whole field.
Therefore, I will introduce two optimisation methods and two sampling methods that are applied within this work.

Both optimisation algorithms in this work are population-based, making use of a population of candidate solutions.
These populations of candidate solutions often have knowledge of the state of each other through some interaction method.
The interaction method is often used to characterise the algorithms, into evolutionary algorithms and swarm intelligence algorithms.\autocite{wu_ensemble_2019}
These population methods are usually more efficient at finding the global minimum for a given search space, than a single candidate method.

\subsection{Differential evolution}
\label{sec:de}
Differential evolution (DE) is a common, iterative optimisation algorithm, that was first applied to the analysis of reflectometry and diffraction data by Wormington \emph{et al.}\autocite{wormington_characterization_1999}
Since then, it has proven very popular for the optimisation of reflectometry data and is included in many common analysis programs.\autocite{bjorck_fitting_2011,bjorck_genx_2007,nelson_co-refinement_2006,nelson_refnx_2019,ott_simulreflec_nodate,kienzle_ncnr_nodate}
The DE algorithm is designed to more ably determine the global minimum of a particular function.\autocite{storn_differential_1997}

DE is an example of a genetic algorithm, one that is designed to mimic the evolution processes observed in biology.\autocite{holland_adaptation_1992}
The method consists of two vectors, the parent population, $\mathbf{p}$, the offspring population, $\mathbf{o}$.
These vectors are of a dimension $(i\times j)$, where $i$ is the number of variables being optimised and $j$ is the number of candidate solutions being used.
The offspring population vector is created through some trial methods.\footnote{Many of these exist however discussion will be limited to a simple classical trial method, details of other methods may be found in \cite{bjorck_fitting_2011}.}

A classical trial method consists of two stages, mutation and recombination.
The mutation stage involves performing some mutation on the parent population to create a mutant vector, $\mathbf{m}$, analogous to the mutation in biological evolutionary theory.
The magnitude of the mutation is dependent on the mutation constant, $k_m$,
%
\begin{equation}
\mathbf{m}_{i,j}= b_{i} + k_m(\mathbf{p}_{i,R1} - \mathbf{p}_{i,R2}),
\end{equation}
%
where $b_{i}$ is the best candidate solution in the parent population, and $\mathbf{p}_{i,R1}$ and $\mathbf{p}_{i,R2}$ are randomly choosen members of the parent population.
The mutation constant can be considered as a control variable for the size of the search radius, with a large $k_m$ corresponding to a larger search radius.

The recombination step creates the offspring population vector by taking a sample from either the parent population or mutant vectors with some frequency, which depends on the recombination constant, $k_r$,
%
\begin{equation}
    \mathbf{o}_{i,j} =
  \begin{cases}
    \mathbf{m}_{i,j}, & \text{where}\ X < k_r \\
    \mathbf{p}_{i,j}, & \text{otherwise}
  \end{cases}
\end{equation}
%
where, $X\sim U[0, 1)$.
The recombination constant controls the progress of the algorithm as it impacts the frequency with which mutation is introduced into the offspring population vector.

The final stage is to compare the offspring and parent population vectors, in the selection stage to create the new parent population for the next iteration.
The selection stage comprises of using some figure of merit, $\zeta$, to choose between the subunit from the offspring or parent population vector.
In our example, that figure of merit may be the agreement between some experimental data and our model, or for the example in Figure~\ref{fig:diff_evo} it is the value of the Ackley function,\autocite{ackley_connectionist_1987} which is being minimised.\footnote{The Ackley function is a common function used for assessing the utility of global optimisation functions.}
%
\begin{equation}
    \mathbf{p}_{*,j} \leftarrow
    \begin{cases}
        \mathbf{o}_{*,j}, & \text{where}\ \zeta_{\mathbf{o}_{*,j}} < \zeta_{\mathbf{p}_{*,j}} \\
        \mathbf{p}_{*,j}, & \text{otherwise}
    \end{cases}
\end{equation}
%
where, the $*$ notation indicates all objects in the given population, and $\zeta_{\mathbf{o}_{*,j}}$ and $\zeta_{\mathbf{p}_{*,j}}$ are the figures of merit for the offspring and population population candidate solutions respectively.
%
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{theory/diff_evo}
    \caption{An example of a differential evolution (DE) algorithm as applied to an Ackley function, where $a=20$, $b=0.2$, and $c=2\pi$. The mutation and recombination constant in this implementation are both $0.5$. Each different coloured line represents a different candidate solution. The optimisation was stopped after $100$ iterations had run.}
    \label{fig:diff_evo}
\end{figure}
%

It is noted that it is often the case,\footnote{In particular for the optimisation of experimental data.} that there should be some bounds applied to the variables within the populations.
However, the DE algorithm may disregard these bounds due to the nature of the mutation step.
Therefore, it is common in DE algorithms, where bounds must be set, that if the search space moves outside that expected it is necessary to reinitialise the parameter.
An implementation of the DE algorithm is given programmatically in Code Block~\ref{cb:diff_evo},\footnote{Additional Code Blocks showing the mutation, recombination, selection steps may be found in Appendix~\ref{diff_evo_app}.} where this reinitialisation is achieved by obtaining a new random number within the given bounds.
%
\begin{listing}
    \centering
    \caption{An example of a simple implementation for a DE algorithm as described in \cite{bjorck_fitting_2011}. The input variables are \texttt{population} which is an array of floats containing the initial parent population, \texttt{f} which is the figure of merit function to be minimised, \texttt{km} which is the mutation constant, \texttt{kr} which is the recombination constant, \texttt{bounds} which is an array of floats giving the minimum and maximum values for the variables, and \texttt{max\_iter} which is the maximum number of iterations that should be performed. This will return \texttt{history} which is a history of the variables that are being fit during the DE algorithm.}
    \lstinputlisting[nolol]{reports/code_blocks/diff_evo.py}
    \label{cb:diff_evo}
\end{listing}
%

\subsection{Particle swarm}
\label{sec:partswarm}
Particle swarm optimisation\footnote{Abbreviated to PSO.} is a type of swarm intelligence population-based optimisation method.
This optimisation method was originally developed by Kennedy, Eberhart, and Shi.\autocite[the initial purpose of the algorithm was to simulate social organisms such as bird flocks]{kennedy_particle_1995,shi_modified_1998}
Particle swarm methods are particularly suitable for the optimisation, and sampling, of parametric search-spaces with a large number of similar minima.
Therefore, I believe that it will be useful for the study of the self-assembly of soft matter materials.\footnote{This is the focus of Chapter~\ref{smallangle}.}

These methods consist of a population vector, similar to that described for the differential evolution, that moves around the parametric search-space.
The motions of these ``particles'' are influenced by the positions of the other particles in the vector.\autocite{poli_analysis_2008}
It is anticipated that this will lead the swarm to optimise the function under investigation.

Particles in the swarm are under the influence of two elastic forces.
The first attracts the particle to the best location in the search-space that the particular particle has found, while the other attracts the particle to the best search-space location found by any particle of the swarm.
The magnitudes of these forces are randomised but modulated by a pair of acceleration coefficients; $\psi_p$ that influences the attraction towards the personal best location and $\psi_g$ that influences the attraction to the global best location.
The position of a particle changes between iterations of the algorithm based on the following relation,
%
\begin{equation}
\mathbf{p}_{*,j} \leftarrow \mathbf{p}_{*,j} + \mathbf{v}_{*,j},
\end{equation}
%
where, $\mathbf{p}_{*,j}$ is the position of the particle, and $\mathbf{v}_{*,j}$ is the velocity of the particle.
This velocity is determined as shown below,
%
\begin{equation}
\mathbf{v}_{*,j} \leftarrow \omega\mathbf{v}_{*,j} + \psi_gR1(\mathbf{g}_{*} - \mathbf{p}_{*,j}) + \psi_pR2(\mathbf{s}_{*,j} - \mathbf{p}_{*,j}),
\end{equation}
%
where, $\omega$ a constant known as the interia weight, $R1\sim U[0, 1)$ and $R2\sim U[0, 1)$ are random numbers, $\mathbf{g}_{*}$ is the best position occupied by any particle in the swarm and $\mathbf{s}_{*,j}$ is the person best for the particle $j$.

Figure~\ref{fig:part_swarm} shows an example of the particle swarm optimisation in action, applied to the Ackley function.\autocite{ackley_connectionist_1987}
Code Block~\ref{cb:part_swarm} shows a functional programmatic implementation of a particle swarm optimisation algorithm.
%
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{theory/part_swarm}
    \caption{An example of a particle swarm optimisation as applied to an Ackley function, where $a=20$, $b=0.2$, and $c=2\pi$. For the particle swarm, the following parameters were used $\omega=0.9$, $\psi_g=0.05$, and $\psi_p=0.05$. Each different coloured line represents a different candidate solution. The optimisation was stopped after \num{100} iterations had run.}
    \label{fig:part_swarm}
\end{figure}
%
\begin{listing}
    \centering
    \caption{An example of the particle swarm optimisation algorithm from \cite{poli_analysis_2008}. The input variables are \texttt{position} which is the initial position vector, \texttt{f} which is the figure of merit function to be minimised, \texttt{omega} which is the interia weight, \texttt{psig} which is the global acceleration constant, \texttt{psip} which is the personal acceleration constant, and the \texttt{max\_iter} which is the maximum number of iterations that should be performed. This will return the \texttt{history} which is a history of the variables that are being fit during the PSO.}
    \lstinputlisting[nolol]{reports/code_blocks/part_swarm.py}
    \label{cb:part_swarm}
\end{listing}
%

\subsection{Markov chain Monte-Carlo}
\label{sec:mcmc}
Markov chain Monte Carlo\footnote{Abbreviated to MCMC.} is a sampling methodology, derived from direct sampling Monte-Carlo.\autocite{krauth_statistical_2006}
The aim of an MCMC algorithm is to sample a probability distribution, when parameters are described in terms of their degree of probability.\autocite{sivia_data_2006}
Similar to MD, in practical terms, MCMC should not be used on a system that is not already optimised, as its purpose is probability distribution sampling rather than minimisation.
Generally, the approach would be to optimise using, for example, one of the approaches described above, then to use MCMC or molecular dynamics to sample the appropriate search-space.
For example, in this work MCMC is used following the optimisation of a reflectometry model using a differential evolution algorithm, to quantify the inverse uncertainties of the model.\footnote{This is the name given to the uncertainties in the parameters fitted in the modelling process.}
In addition to being able to give information about the inverse uncertainties, MCMC also offers a more complete understanding of the correlations present between the different parameters,\autocite{gilks_markov_1995} as the interactions between the parameter variation has been quantified.

The aim of MCMC is to only sample configurations of a given function that are within the experimental uncertainty.
Figure~\ref{fig:mcmc} shows an example of the possible output that may be obtained from the application of an MCMC sampling method.
This was generated using a Metropolis-Hastings MCMC algorithm,\autocite{metropolis_equation_1953,hastings_monte_1970} shown in Code Block~\ref{cb:mcmc}.
Initially, a Levenberg–Marquardt algorithm\autocite{levenberg_method_1944,marquardt_algorithm_1963} was used to optimise the positions and integral of the two Gaussian functions that make up the data.
The MCMC was used to sample the values that were within the experimental uncertainty.
%
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{theory/mcmc}
    \caption{An example of a four variable (two nearby Gaussian functions of different sizes with added random noise and some fractional uncertainty) problem probed using a MCMC method, using values of $a=0.1$, $\theta_1$ and $\theta_2$ correspond to the integral of the Gaussian function, while $\theta_3$ and $\theta_4$ indicate their positions; (a)-(d) histograms of the probability distribution function for each of the varibles, and (e) the data (blue circles), the optimised solution (orange line), and a series of probable solutions (green lines) showing the variability present in the data uncertainty.}
    \label{fig:mcmc}
\end{figure}
%
\begin{listing}
    \centering
    \caption{An example of the Metropolis-Hastings MCMC algorithm from \cite{metropolis_equation_1953,hastings_monte_1970}. The input variables are \texttt{theta} which is an array of floats giving the initial values for the variables, \texttt{f} which is the figure of merit function to be minimised, \texttt{a} which is the step size for the changes, \texttt{data} which is the experimental data, \texttt{iterations} which is the number of accepted iterations to obtain, and \texttt{nburn} which is the number of accepted iteractions to ignore in the burn-in phase. This will return the \texttt{history} which is a history of the variables that are being fit during the PSO.}
    \lstinputlisting[nolol]{reports/code_blocks/mcmc.py}
    \label{cb:mcmc}
\end{listing}
%

Once an optimised solution, $\theta$, is obtained, the figure of metric is calculated, in Code Block~\ref{cb:mcmc} this is the agreement between the model and the experimental data, $\chi^2$, where,
%
\begin{equation}
\chi^2 = \sum\frac{(y_{\text{exp}} - y_{\text{calc}})^2}{\text{d}y_{\text{exp}}},
\end{equation}
%
and $y_{\text{exp}}$ is the experimental data, and $\text{d}y_{\text{exp}}$ the uncertainty in the experimental data, while $y_{\text{calc}}$ is the model solution.
Some random pertubation is then applied to the optimised solution,
%
\begin{equation}
\Theta = \theta + aR,
\end{equation}
%
where $R\sim N(0, 1)$ and $a$ is the step size.
A new $\chi^2$ is found for $\Theta$, and the probablity that this transition will occur is found,
%
\begin{equation}
p = \exp{\bigg(\frac{-\chi^2(\Theta) + \chi^2(\theta)}{2}\bigg)}.
\end{equation}
%
This probability is then compared with a random number $n\sim~U[0, 1)$, and if $n$ is less than the probability, the new solution is stored,
%
\begin{equation}
\theta \leftarrow \Theta.
\end{equation}
%
This process is repeated until some desired number of samples has been obtained.
It should be noted that in the event on a poorly optimised initial value of $\theta$, it may be necessary to `burn'\footnote{This means to ignore.} the first series of solutions while the MCMC algorithm settles into the search-space.

\subsection{Molecular dynamics}
\label{sec:md}
Section \ref{sec:classical} introduced classical potential models as a method for the evalution of the interaction energy of a given chemical system.
Any of the optimisation methods discussed above could be used alongside these classical potential models to find an energy minimum structure for the system or to sample the potential energy landscape.
However, it is often the case that a dynamically relevant structure is of interest at a given temperature.
This is where molecular dynamics simulations are a useful and important tool.

The aim of a molecular dynamics simulation is to probe the positions, velocities, and accelerations on each of the atoms, or coarse-grained particles, as a simulation progresses.
The acceleration on a given particle, $\mathbf{a}$ is defined by the force on that particle, $\mathbf{f}$, in agreement with Newton's second law of motion,
%
\begin{equation}
\mathbf{f} = m\mathbf{a},
\label{equ:forcevec}
\end{equation}
%
where, $m$ is the mass of the particle.
In order to determine the acceleration on the particle, it is necessary to know the force on that particle.
The force, $f$, is a function of the potential energy, $E$, as found from a classical potential, of that atom,
%
\begin{equation}
f(r) = \frac{-\delta E_{\text{total}}(r)}{\delta r},
\label{equ:forcesca}
\end{equation}
%
where, $r$ is the configuration of the atoms.\footnote{The force is the negative of the first derivative of the energy with respect to the atomic configuration.}
The force found from Equation~\ref{equ:forcesca} is a scalar, however, the force vector is present in Equation~\ref{equ:forcevec}.
To determine the force in a given direction, it is necessary to find the product of the force, $f$, and the unit vector in that direction,
%
\begin{equation}
\mathbf{f}_x = f\hat{\mathbf{r}}_x, \;\;\;\text{where}\;\hat{\mathbf{r}}_x = \frac{r_x}{|\mathbf{r}|},
\end{equation}
%
where $r_x$ is the atomic configuration in the $x$-dimension, and $|\mathbf{r}|$ is the magnitude of the atomic configuration vector.

The potential model, which is defined for a given system, allows for the calculation of the acceleration on each particle in that system.
The next step is to use this acceleration to iterate through the trajectory of our system.
This is achieved by applying Newtonian equations of motion, for example in the Velocity-Verlet algorithm.\autocite{swope_computer_1982}
%
\begin{equation}
\mathbf{x}(t + \Delta t) = \mathbf{x}(t) + \mathbf{v}(t)\Delta t + \frac{1}{2}\mathbf{a}(t)\Delta t^2,
\label{equ:vv1}
\end{equation}
\begin{equation}
\mathbf{v}(t + \Delta t) = \mathbf{v}(t) + \frac{1}{2}\big[\mathbf{a}(t) + \mathbf{a}(t+\Delta t)\big]\Delta t,
\label{equ:vv2}
\end{equation}
%
where, $\mathbf{x}$ is the position the particle $\mathbf{v}$ is the particle's velocity, and $\mathbf{a}$ is the particle's acceleration, while $t$ is current simulation time and $\Delta t$ is the timestep.
These equations constitute the Velocity-Verlet algorithm,
%
\begin{enumerate}
\item calculate the force,and therefore the acceleration, on each particle,\footnote{Using Equations~\protect\ref{equ:forcevec} \& \protect\ref{equ:forcesca}.}
\item find the position of the particle after some timestep,\footnote{Using Equation~\protect\ref{equ:vv1}.}
\item determine the new velocity for each particle, based on the average acceleration at the current and new positions,\footnote{Using Equation~\protect\ref{equ:vv2}.}
\item overwrite the old acceleration values with the new ones,
\item go to 1.
\end{enumerate}
%
Following an equilibration period, this algorithm may be iterated as many times as is required to obtain sufficient statistics for the measurement quantity of interest, e.g. particle positions for structural techniques such as elastic scattering.

The above analytical process is known as the integration step, and the Velocity-Verlet is the integrator.
If the size of the timestep $\Delta t$ is too large, the step size for a given iteration will not be accurate, as the forces on the atoms will change too significantly during it.
Therefore, the values of the timestep is usually on the order of \SI{10e-15}{\second}.\footnote{femtoseconds.}
This means that in order to simulate a single nanosecond of ``real-time'' molecular dynamics, the integrator must be solved one million times.
This can be slow for very large systems, leading to an interest in coarse-grained simulations that result in fewer particles to determine the forces for, but also enable to use of larger timesteps,\autocite[so fewer, faster integration steps must be solved]{rudd_coarse-grained_1998,brini_systematic_2013} for example, the use of a MARTINI potential model allows for an upto twenty times increase in the timestep compared to an all-atom model.

The above discussion ignored two aspects that are necessary to run a molecular dynamics simulation, both of which as associated with the original configuration of the system; the original particle positions and velocities.
The particle positions are usually taken from some library, for example for the simulation of a protein, often the protein data bank\autocite{noauthor_rcsb_nodate} is a useful resource.
Small molecules may be configured by hand using graphical programs such as Jmol.\autocite{noauthor_jmol_nodate}
These small molecules may be built into complex, multicomponent structures using software such as the Packmol package.\autocite{martinez_packmol_2009}
The importance of this initial structure cannot be overstated, for example, if the initial structure in a molecular dynamics simulation is unrepresentative of the equilibrium structure, it may take a large amount of simulation time before the equilibrium structure is obtained.\footnote{This can be much longer than could be reasonably simulated.}

The initial particle velocities are obtained in a much more general fashion.
They are selected randomly, and then scaled such that the kinetic energy, $E_k$, of the system agrees with a defined temperature, $T$,
%
\begin{equation}
E_k = \sum_{i=1}^N{\frac{m_i|\mathbf{v}_i|^2}{2}} = \frac{3}{2}Nk_BT,
\label{equ:ek}
\end{equation}
%
where, $m_i$ and $\mathbf{v}_i$ are the masses and velocities of the particles, $N$ is the number of particles, and $k_B$ is the Boltzmann constant.

The above algorithm details a simulation that makes use of an NVE ensemble.\footnote{A simulation where the number of particles (N), the volume of the system (V), the energy of the system (E) are all kept constant.}
However, this is not the only simulation ensemble that is available, within this work two other ensembles have been used extensively,
%
\begin{itemize}
\item the NVT (canonical) ensemble; this is similar to the NVE ensemble except the simulation temperature is controlled via a thermostat,
\item the NPT (isothermal-isobaric); this ensemble is similar to the NVT ensemble, however, the system volume is allowed to vary while the overall system pressure is held constant using a barostat.
\end{itemize}
%
Thermostating involves controlling the kinetic energy of the particles\footnote{Using Equation~\ref{equ:ek}.} such that the simulation temperature is kept at a predefined value.
There are a variety of methods for thermostating a molecular dynamics simulation, such as the Andersen, Nos\'{e}-Hoover, or Berendsen methods.\autocite{andersen_molecular_1980,nose_unified_1984,berendsen_molecular_1984,hoover_canonical_1985}
However, the most straightforward to describe, and that implemented in the \texttt{pylj} software\autocite[Discussed in detail in Chapter \ref{teaching}]{mccluskey_pylj_2018,mccluskey_arm61/pylj_2018} is a velocity rescaling.\autocite{bussi_canonical_2007}
This is where the velocities for a random subset of the particles, $\mathbf{v}_i$ are adapted based on the following relation,
%
\begin{equation}
\mathbf{v}_i \leftarrow \mathbf{v}_i \sqrt{\frac{T_{\text{target}}}{\bar{T}}}
\end{equation}
%
where, $T_{\text{target}}$ is the target temperature, and $\bar{T}$ is the average simulation temperature.

The use of a barostat to control the simulation pressure usually involves varying the simulation cell parameters and the distances between the particles.
This would in a similar way to thermostating, where the simulation dimensions are scaled by a value in an effort to control the pressure.
The barostating methods are similar to the thermostating methods with Andersen, Nos\'{e}-Hoover, and Berendsen methods.
However, there is also the Parrinello-Rahman barostat which allows for independent control of the different cell dimensions giving control of stress in addition to pressure.\autocite{parrinello_polymorphic_1981}

These optimisation and sampling methods were used in a variety of different applications within this work, firstly differential evoluation optimisation and MCMC sampling are used in Chapter~\ref{reflectometry1} in the study of a chemically-consistent modelling approach to X-ray and neutron reflectometry analysis.
Molecular dynamics simulation are investigated as a possible tool to assist in the analysis of reflectometry in in Chapter~\ref{reflectometry2}.
Finally, the particle swarm optimisation is applied for the efficient determination of a micelle structure for ftting small angle scattering data in Chapter~\ref{smallangle}.
